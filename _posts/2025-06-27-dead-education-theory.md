---
layout: single
title: "Dead Education Theory"
excerpt: "What if the real threat of AI in education isn’t cheating—but hollowness? In this post, we explore Dead Education Theory: a growing pattern where AI writes the assignments, completes them, grades them, and no real learning happens at all. It’s not about banning tools—it’s about designing systems that keep humanity at the heart of the classroom."
tags: [education, ai, integrity]
header:
  overlay_image: /assets/images/blog/dead-education-theory/dead_education_header.jpg
  overlay_filter: 0.5
---

I think we’d all agree that the internet feels… less human, and if I’m being completely honest, more pointless these days.

Content is increasingly spun up by algorithms for other algorithms to amplify, leaving genuine humanity stranded on the sidelines.

That hollow sensation has a name: Dead Internet Theory. You’ve surely felt this yourself, picture every social media feed nowadays. That endless stream of TikTok-style clips stitched from stock footage, capped with a perky synthetic narrator: “Here are five productivity hacks you won’t believe!” The AI-generated video exists only so a recommendation AI can serve it to another AI bot that dutifully clicks “like.” The cycle rolls on. It’s a perpetual-motion machine whose sole product is futile noise.

![Feedback loop showing robots talking to robots](/assets/images/blog/dead-education-theory/dead-internet-cycle.png)

Lately I’ve been wondering if the same dynamic is seeping into our classrooms. Let’s call it Dead Education Theory. Imagine the following:

* A professor uses AI to draft a rubric and assignment prompt for their class (as enabled by any one of many dozens of free and commercial tools).
* A student pastes that prompt into another AI, gets an essay back, and submits (this behavior is becoming common, with a large fraction of submitted essays in colleges showing the hallmarks of AI use).
* The professor, pressed for time, runs it through an AI that spits out tidy boilerplate feedback (see, for example, the student suing Northeastern University after she discovered feedback on her paper was generated by ChatGPT)
* Off to the side, originality checkers and paraphrasing bots duel in an endless game of evasion and detection.

On paper, the learning loop is complete.  The essay is written.

The existence of the end product aside, no moment of human interaction, struggle, or learning ever happened, just people watching progress bars while mathematical models spat out text.

I firmly believe this pattern is already happening hundreds, if not thousands, of times every day.  The attraction of AI-powered time-savings is just too sharp.

What, then, if this is taken to its logical conclusion?  We’re dutifully performing a ritual whose purpose has drifted away, like lighthouse keepers polishing the lenses even after the shipping lanes have moved.

Where’s the human spark—the struggle, insight, revision that schooling is meant to cultivate? Banning the tools isn’t realistic; the genie’s out. But we can design for a future where AI amplifies authentic thinking instead of hollowing it out.

This is the flag I want to plant in the ground.  Human-centric education in a world where we have to work alongside AI is what we have been building -- and continue to build -- at  Packback.  We need platforms that shove students (and professors) into the messy, collaborative middle of learning. AI will be in the classroom; the important question to my mind is how we keep humanity there, too.
